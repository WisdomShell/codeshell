
<p align="center">
    <img src="https://cdn-uploads.huggingface.co/production/uploads/6489a27bd0b2fd1f3297e5ca/3LQsqRzluBhBN2DipN6Ox.png" width="400"/>
<p>

<p align="center">
  ğŸ¤— <a href="https://huggingface.co/WisdomShell/CodeShell" target="_blank">Hugging Face</a> â€¢ ğŸŒ <a href="http://se.pku.edu.cn/kcl/" target="_blank">PKU-KCL</a> 
</p>

<div align="center">

[![license](https://img.shields.io/github/license/modelscope/modelscope.svg)](https://github.com/WisdomShell/codeshell/blob/main/LICENSE)
<h4 align="center">
    <p><a href="https://github.com/WisdomShell/codeshell/blob/main/README.md"><b>ä¸­æ–‡</b></a>|<a href="https://github.com/WisdomShell/codeshell/blob/main/README_EN.md">English</a></p>
</h4>
</div>

## Introduction

CodeShellæ˜¯[åŒ—äº¬å¤§å­¦çŸ¥è¯†è®¡ç®—å®éªŒå®¤](http://se.pku.edu.cn/kcl/)è”åˆå››å·å¤©åºœé“¶è¡ŒAIå›¢é˜Ÿç ”å‘çš„å¤šè¯­è¨€ä»£ç å¤§æ¨¡å‹åŸºåº§ã€‚CodeShellå…·æœ‰70äº¿å‚æ•°ï¼Œåœ¨äº”åƒäº¿Tokensè¿›è¡Œäº†è®­ç»ƒï¼Œä¸Šä¸‹æ–‡çª—å£é•¿åº¦ä¸º8192ã€‚åœ¨æƒå¨çš„ä»£ç è¯„ä¼°Benchmarkï¼ˆHumanEvalä¸MBPPï¼‰ä¸Šï¼ŒCodeShellå–å¾—åŒç­‰è§„æ¨¡æœ€å¥½çš„æ€§èƒ½ã€‚ä¸æ­¤åŒæ—¶ï¼Œæˆ‘ä»¬æä¾›äº†ä¸CodeShellé…å¥—çš„éƒ¨ç½²æ–¹æ¡ˆä¸IDEæ’ä»¶ï¼Œè¯·å‚è€ƒä»£ç åº“[CodeShell](https://github.com/WisdomShell/codeshell)ã€‚åŒæ—¶ï¼Œä¸ºäº†æ–¹ä¾¿ä¸­å›½ç”¨æˆ·ä¸‹è½½ï¼Œæˆ‘ä»¬åœ¨modelscopeä¸­ä¹Ÿä¸Šä¼ äº†å¯¹åº”ç‰ˆæœ¬ï¼Œå›½å†…ç”¨æˆ·å¯ä»¥è®¿é—®[CodeShellå›½å†…åœ°å€](https://modelscope.cn/organization/WisdomShell)ã€‚


æœ¬æ¬¡å¼€æºçš„æ¨¡å‹å¦‚ä¸‹ï¼š

- <a href="https://huggingface.co/WisdomShell/CodeShell" target="_blank"><b>CodeShell Base</b></a>ï¼šCodelShellåº•åº§æ¨¡å‹ï¼Œå…·æœ‰å¼ºå¤§çš„ä»£ç åŸºç¡€èƒ½åŠ›ã€‚
- <a href="https://huggingface.co/WisdomShell/CodeShell-Chat" target="_blank"><b>CodeShell Chat</b></a>ï¼šCodelShellå¯¹è¯æ¨¡å‹ï¼Œåœ¨ä»£ç é—®ç­”ã€ä»£ç è¡¥å…¨ç­‰ä¸‹æ¸¸ä»»åŠ¡é‡æ€§èƒ½ä¼˜å¼‚ã€‚
- <a href="https://huggingface.co/WisdomShell/CodeShell-Chat-int4" target="_blank"><b>CodeShell Chat 4bit</b></a>ï¼šCodelShellå¯¹è¯æ¨¡å‹4bité‡åŒ–ç‰ˆæœ¬ï¼Œåœ¨ä¿è¯æ¨¡å‹æ€§èƒ½çš„å‰æä¸‹å†…å­˜æ¶ˆè€—æ›´å°ï¼Œé€Ÿåº¦æ›´å¿«ã€‚
- <a href="https://github.com/WisdomShell/llama_cpp_for_codeshell" target="_blank"><b>CodeShell CPP</b></a>ï¼šCodelShellå¯¹è¯æ¨¡å‹CPPç‰ˆæœ¬ï¼Œæ”¯æŒå¼€å‘è€…åœ¨æ²¡æœ‰GPUçš„ä¸ªäººç”µè„‘ä¸­ä½¿ç”¨ã€‚æ³¨æ„ï¼ŒCPPç‰ˆæœ¬åŒæ ·æ”¯æŒé‡åŒ–æ“ä½œï¼Œç”¨æˆ·å¯ä»¥åœ¨æœ€å°å†…å­˜ä¸º8Gçš„ä¸ªäººç”µè„‘ä¸­è¿è¡ŒCodeShellã€‚


## Main Characteristics of CodeShell

- **å¼ºå¤§çš„æ€§èƒ½**ï¼šCodelShellåœ¨HumanEvalå’ŒMBPPä¸Šè¾¾åˆ°äº†7Bä»£ç åŸºåº§å¤§æ¨¡å‹çš„æœ€ä¼˜æ€§èƒ½
- **å®Œæ•´çš„ä½“ç³»**ï¼šé™¤äº†ä»£ç å¤§æ¨¡å‹ï¼ŒåŒæ—¶å¼€æºIDEï¼ˆVS Codeä¸JetBrainsï¼‰æ’ä»¶ï¼Œå½¢æˆå¼€æºçš„å…¨æ ˆæŠ€æœ¯ä½“ç³»
- **è½»é‡åŒ–éƒ¨ç½²**ï¼šæ”¯æŒæœ¬åœ°C++éƒ¨ç½²ï¼Œæä¾›è½»é‡å¿«é€Ÿçš„æœ¬åœ°åŒ–è½¯ä»¶å¼€å‘åŠ©æ‰‹è§£å†³æ–¹æ¡ˆ
- **å…¨é¢çš„è¯„æµ‹**ï¼šæä¾›æ”¯æŒå®Œæ•´é¡¹ç›®ä¸Šä¸‹æ–‡ã€è¦†ç›–ä»£ç ç”Ÿæˆã€ä»£ç ç¼ºé™·æ£€æµ‹ä¸ä¿®å¤ã€æµ‹è¯•ç”¨ä¾‹ç”Ÿæˆç­‰å¸¸è§è½¯ä»¶å¼€å‘æ´»åŠ¨çš„å¤šä»»åŠ¡è¯„æµ‹ä½“ç³»ï¼ˆå³å°†å¼€æºï¼‰
- **é«˜æ•ˆçš„è®­ç»ƒ**ï¼šåŸºäºé«˜æ•ˆçš„æ•°æ®æ²»ç†ä½“ç³»ï¼ŒCodeShellåœ¨å®Œå…¨å†·å¯åŠ¨æƒ…å†µä¸‹ï¼Œåªè®­ç»ƒäº†äº”åƒäº¿Tokenå³è·å¾—äº†ä¼˜å¼‚çš„æ€§èƒ½

## Performance

æˆ‘ä»¬é€‰å–äº†ç›®å‰æœ€æµè¡Œçš„ä¸¤ä¸ªä»£ç è¯„æµ‹æ•°æ®é›†ï¼ˆHumanEvalä¸MBPPï¼‰å¯¹æ¨¡å‹è¿›è¡Œè¯„ä¼°ï¼Œä¸ç›®å‰æœ€å…ˆè¿›çš„ä¸¤ä¸ª7bä»£ç å¤§æ¨¡å‹CodeLllamaä¸Starcoderç›¸æ¯”ï¼ŒCodeshell å–å¾—äº†æœ€ä¼˜çš„æˆç»©ã€‚å…·ä½“è¯„æµ‹ç»“æœå¦‚ä¸‹ã€‚

|   ä»»åŠ¡   |  CodeShell-7b | CodeLlama-7b | Starcoder-7b |
| ------- | --------- | --------- | --------- |
| humaneval	 | **34.32** | 29.44 | 27.80 |
| mbpp		 | **38.65** | 37.60 | 34.16 |
| multiple-js	 | **33.17** | 31.30 | 27.02 |
| multiple-java	 | **30.43** | 29.24 | 24.30 |
| multiple-cpp	 | **28.21** | 27.33 | 23.04 |
| multiple-swift | 24.30 | **25.32** | 15.70 |
| multiple-php	 | **30.87** | 25.96 | 22.11 |
| multiple-d	 | 8.85 | **11.60** | 8.08 |
| multiple-jl	 | 22.08 | **25.28** | 22.96 |
| multiple-lua	 | 22.39 | **30.50** | 22.92 |
| multiple-r	 | **20.52** | 18.57 | 14.29 |
| multiple-rkt	 | **17.20** | 12.55 | 10.43 |
| multiple-rs	 | 24.55 | **25.90** | 22.82 |

## Requirements

- python 3.8 and above
- pytorch 2.0 and above are recommended
- transformers 4.32 and above
- CUDA 11.8 and above are recommended (this is for GPU users, flash-attention users, etc.)

## Quickstart

CodeShellç³»åˆ—æ¨¡å‹å·²ç»ä¸Šä¼ è‡³ <a href="https://huggingface.co/WisdomShell/CodeShell" target="_blank">Hugging Face</a>ï¼Œå¼€å‘è€…å¯ä»¥é€šè¿‡Transformerså¿«é€Ÿè°ƒç”¨CodeShellå’ŒCodeShell-Chatã€‚

åœ¨å¼€å§‹ä¹‹å‰ï¼Œè¯·ç¡®ä¿å·²ç»æ­£ç¡®è®¾ç½®äº†ç¯å¢ƒï¼Œå¹¶å®‰è£…äº†å¿…è¦çš„ä»£ç åŒ…ï¼Œä»¥åŠæ»¡è¶³ä¸Šä¸€å°èŠ‚çš„ç¯å¢ƒè¦æ±‚ã€‚ä½ å¯ä»¥é€šè¿‡ä¸‹åˆ—ä»£ç å¿«é€Ÿå®‰è£…ç›¸å…³ä¾èµ–ã€‚

```
pip install -r requirements.txt
```

æ¥ä¸‹æ¥ä½ å¯ä»¥é€šè¿‡Transformersä½¿ç”¨CodeShellã€‚

### Code Generation

å¼€å‘è€…å¯ä»¥ä½¿ç”¨CodeShellå¿«é€Ÿç”Ÿæˆä»£ç ï¼ŒåŠ é€Ÿå¼€å‘æ•ˆç‡ã€‚

```python
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer

device = 'cuda' if torch.cuda.is_available() else 'cpu'
tokenizer = AutoTokenizer.from_pretrained("WisdomShell/CodeShell-7B")
model = AutoModelForCausalLM.from_pretrained("WisdomShell/CodeShell-7B", trust_remote_code=True, torch_dtype=torch.bfloat16).to(device)
inputs = tokenizer('def merge_sort():', return_tensors='pt').to(device)
outputs = model.generate(**inputs)
print(tokenizer.decode(outputs[0]))
```

- Fill in the Moddle

CodeShell æ”¯æŒFill-in-the-Middleæ¨¡å¼ï¼Œä»è€Œæ›´å¥½çš„æ”¯æŒè½¯ä»¶å¼€å‘è¿‡ç¨‹ã€‚

```python
input_text = "<fim_prefix>def print_hello_world():\n    <fim_suffix>\n    print('Hello world!')<fim_middle>"
inputs = tokenizer(input_text, return_tensors='pt').to(device)
outputs = model.generate(**inputs)
print(tokenizer.decode(outputs[0]))
```

- ä»£ç é—®ç­”

CodeShellåŒæ—¶å¼€æºäº†ä»£ç åŠ©æ‰‹æ¨¡å‹CodeShell-7B-Chatï¼Œå¼€å‘è€…å¯ä»¥é€šè¿‡ä¸‹åˆ—ä»£ç ä¸æ¨¡å‹è¿›è¡Œäº¤äº’ã€‚

```python
model = AutoModelForCausalLM.from_pretrained('WisdomShell/CodeShell-7B-Chat', trust_remote_code=True, torch_dtype=torch.bfloat16).to(device)
tokenizer = AutoTokenizer.from_pretrained('WisdomShell/CodeShell-7B-Chat')

history = []
query = 'ä½ æ˜¯è°?'
response = model.chat(query, history, tokenizer)
print(response)
history.append((query, response))

query = 'ç”¨Pythonå†™ä¸€ä¸ªHTTP server'
response = model.chat(query, history, tokenizer)
print(response)
history.append((query, response))
```

å¼€å‘è€…ä¹Ÿå¯ä»¥é€šè¿‡VS Codeä¸JetBrainsæ’ä»¶ä¸CodeShell-7B-Chatäº¤äº’ï¼Œè¯¦æƒ…è¯·å‚[VSCodeæ’ä»¶ä»“åº“](https://github.com/WisdomShell/codeshell-vscode)ä¸[IntelliJæ’ä»¶ä»“åº“](https://github.com/WisdomShell/codeshell-intellij)ã€‚


- Model Quantization

CodeShell æ”¯æŒ4 bit/8 bité‡åŒ–ï¼Œ4 bité‡åŒ–åï¼Œå ç”¨æ˜¾å­˜å¤§å°çº¦6Gï¼Œç”¨æˆ·å¯ä»¥åœ¨æ˜¾å­˜è¾ƒå°çš„GPUä¸Šä½¿ç”¨CodeShellã€‚

```python
model = AutoModelForCausalLM.from_pretrained('WisdomShell/CodeShell-7B-Chat-int4', trust_remote_code=True).to(device)
tokenizer = AutoTokenizer.from_pretrained('WisdomShell/CodeShell-7B-Chat-int4')
```

- CodeShell in c/c++

ç”±äºå¤§éƒ¨åˆ†ä¸ªäººç”µè„‘æ²¡æœ‰GPUï¼ŒCodeShellæä¾›äº†C/C++ç‰ˆæœ¬çš„æ¨ç†æ”¯æŒï¼Œå¼€å‘è€…å¯ä»¥æ ¹æ®æœ¬åœ°ç¯å¢ƒè¿›è¡Œç¼–è¯‘ä¸ä½¿ç”¨ï¼Œè¯¦è§[CodeShell C/C++æœ¬åœ°åŒ–ç‰ˆ](https://github.com/WisdomShell/llama_cpp_for_codeshell)ã€‚

## Demo

æˆ‘ä»¬æä¾›äº†Web-UIã€å‘½ä»¤è¡Œã€APIã€IDEå››ç§å½¢å¼çš„Demoã€‚

### Web UI

å¼€å‘è€…é€šè¿‡ä¸‹åˆ—å‘½ä»¤å¯åŠ¨WebæœåŠ¡ï¼ŒæœåŠ¡å¯åŠ¨åï¼Œå¯ä»¥é€šè¿‡`https://127.0.0.1:8000`è¿›è¡Œè®¿é—®ã€‚

```
python demos/web_demo.py
```

### CLI Demo

æˆ‘ä»¬ä¹Ÿæä¾›äº†å‘½ä»¤è¡Œäº¤äº’çš„Demoç‰ˆæœ¬ï¼Œå¼€å‘è€…å¯ä»¥é€šè¿‡ä¸‹åˆ—å‘½ä»¤è¿è¡Œã€‚

```
python demos/cli_demo.py
```

### API

CodeShellä¹Ÿæä¾›äº†åŸºäºOpenAI APIçš„éƒ¨ç½²æ–¹æ³•ã€‚

```
python demos/openai_api.py
```

å¯åŠ¨åå³å¯é€šè¿‡HTTPè¯·æ±‚ä¸CodeShelläº¤äº’ã€‚

```
curl http://127.0.0.1:8000/v1/chat/completions \
  -H "Content-Type: application/json" \
  -d '{
    "model": "CodeShell-7B-Chat",
    "messages": [
      {
        "role": "user",
        "content": "ä½ å¥½"
      }
    ]
  }'
```

### IDE

CodeShellæœ€åæä¾›äº†çº¿ä¸ŠIDEï¼Œå¼€å‘è€…å¯ä»¥é€šè¿‡IDEè¿›è¡Œä»£ç è¡¥å…¨ã€ä»£ç é—®ç­”ç­‰æ“ä½œã€‚åŒæ—¶ï¼ŒIDEæ’ä»¶ä¹ŸåŒæ—¶å‘å¸ƒï¼Œå¼€å‘è€…å¯ä»¥è‡ªè¡Œåœ¨æœ¬åœ°è¿›è¡Œå®‰è£…ä½¿ç”¨ã€‚æ’ä»¶ç›¸å…³é—®é¢˜æ¬¢è¿åœ¨[VSCodeæ’ä»¶ä»“åº“](https://github.com/WisdomShell/codeshell-vscode)ä¸[IntelliJæ’ä»¶ä»“åº“](https://github.com/WisdomShell/codeshell-intellij)ä¸­è®¨è®ºã€‚

## Model Details

Code Shellä½¿ç”¨GPT-2ä½œä¸ºåŸºç¡€æ¶æ„ï¼Œé‡‡ç”¨Grouped-Query Attentionã€RoPEç›¸å¯¹ä½ç½®ç¼–ç ç­‰æŠ€æœ¯ã€‚

### Hyper-parameter

| Hyper-parameter | Value  |
|---|---|
| n_layer | 42 |
| n_embd | 4096 |
| n_inner | 16384 |
| n_head | 32 |
| num_query_groups | 8 |
| seq-length | 8192 |
| vocab_size | 70144 |


### Data

CodeShellåŸºäºè‡ªå·±çˆ¬å–çš„Githubæ•°æ®ã€Big Codeå¼€æºçš„Stackå’ŒStarCoderæ•°æ®é›†ã€ä»¥åŠå°‘é‡é«˜è´¨é‡çš„ä¸­è‹±æ–‡æ•°æ®è¿›è¡Œè®­ç»ƒã€‚åœ¨åŸå§‹æ•°æ®é›†çš„åŸºç¡€ä¸Šï¼ŒCodeShellé‡‡ç”¨åŸºäºMinihashå¯¹æ•°æ®å»é‡ï¼ŒåŸºäºKenLMä»¥åŠé«˜è´¨é‡æ•°æ®ç­›é€‰æ¨¡å‹å¯¹æ•°æ®è¿›è¡Œäº†è¿‡æ»¤ä¸ç­›é€‰ï¼Œæœ€ç»ˆå¾—åˆ°é«˜è´¨é‡çš„é¢„è®­ç»ƒæ•°æ®é›†ã€‚

### Tokenizer

CodeShellåŸºäºStarcoderè¯è¡¨è¿›è¡Œäº†ä¼˜åŒ–ï¼Œå»é™¤äº†ä½¿ç”¨é¢‘ç‡è¾ƒä½çš„è¯è¯­ï¼Œå¹¶æ·»åŠ äº†éƒ¨åˆ†ä¸­æ–‡è¯è¡¨ï¼Œæ˜¾è‘—æå‡äº†ä¸­æ–‡çš„å‹ç¼©ç‡ï¼Œä¸ºChatç‰ˆæœ¬çš„è®­ç»ƒæä¾›äº†åŸºç¡€ã€‚


| Tokenizer | Size | Chinese  | English | Code | Total|
|---|---|---|---|---|---|
| Starcoder | 49152 | 1.22 | 3.47 | 3.30 | 2.66 |
| CodeShell | 70020 | 1.50 | 3.47 | 3.30 | 2.95 |


## License

ç¤¾åŒºä½¿ç”¨CodeShellæ¨¡å‹éœ€è¦éµå¾ªã€ŠCodeShellæ¨¡å‹è®¸å¯åè®®ã€‹åŠApache 2.0è®¸å¯åè®®ã€‚CodeShellæ¨¡å‹å…è®¸ç”¨äºå•†ä¸šç”¨é€”ï¼Œä½†å¦‚æœæ‚¨è®¡åˆ’å°†CodeShellæ¨¡å‹æˆ–å…¶æ´¾ç”Ÿäº§å“ç”¨äºå•†ä¸šç”¨é€”ï¼Œéœ€è¦æ‚¨ç¡®è®¤ä¸»ä½“ç¬¦åˆä»¥ä¸‹æ¡ä»¶ï¼š

1. å…³è”æ–¹çš„æœåŠ¡æˆ–äº§å“çš„æ¯æ—¥å¹³å‡æ´»è·ƒç”¨æˆ·æ•°ï¼ˆDAUï¼‰ä¸èƒ½è¶…è¿‡100ä¸‡ã€‚
2. å…³è”æ–¹ä¸å¾—æ˜¯è½¯ä»¶æœåŠ¡æä¾›å•†æˆ–äº‘æœåŠ¡æä¾›å•†ã€‚
3. å…³è”æ–¹ä¸å­˜åœ¨å°†è·å¾—æˆäºˆçš„å•†ä¸šè®¸å¯ï¼Œåœ¨æœªç»è®¸å¯çš„å‰æä¸‹å°†å…¶å†æˆæƒç»™å…¶ä»–ç¬¬ä¸‰æ–¹çš„å¯èƒ½æ€§ã€‚

åœ¨æ»¡è¶³ä¸Šè¿°æ¡ä»¶çš„å‰æä¸‹ï¼Œæ‚¨éœ€è¦é€šè¿‡å‘codeshell.opensource@gmail.comå‘é€ç”µå­é‚®ä»¶æäº¤ç”³è¯·ã€‚ç»å®¡æ ¸é€šè¿‡åï¼Œå°†æˆäºˆæ‚¨ä¸€ä¸ªå…¨çƒçš„ã€éæ’ä»–çš„ã€ä¸å¯è½¬è®©çš„ã€ä¸å¯å†æˆæƒçš„å•†ä¸šç‰ˆæƒè®¸å¯ã€‚


## Star History

[![Star History Chart](https://api.star-history.com/svg?repos=WisdomShell/codeshell&type=Date)](https://star-history.com/#WisdomShell/codeshell&Date)

